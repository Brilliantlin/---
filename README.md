# Global Artificial Intelligence Technology Innovation Competition (Track One) share

经过几周的奋斗，终于在不是那么靠前的位置捡漏了一个周星星。首先感谢前面所有周周星大佬分享的思路以及群里面大家的讨论，对我启发颇多。目前最好成绩是2个深度学习模型+1个预训练模型，三个单模都在0.911左右，下面简单的分享下我的做法：

1. 数据方面，通过数据探索发现训练集测试集的分布基本一致，包括词频和长度。但是大家都遇到的问题是线上线上不一致的问题，所以可以从解决过拟合方面下手，做的操作有数据增强（替换以及随机掩盖）、dropout等，数据增强可以看作增加数据噪声，让模型更具鲁棒性。
3. 词向量方面，词向量表示的好坏直接影响到后面模型的效果，目前用到的词向量是目前常用是w2v、fasttext、glove
4. 模型方面，机器学习模型尝试过基于分类器链的树模型，特征使用tf-idf,效果不是很好大概0.84左右；深度学习模型尝试了很多种，主要是RNN\CNN以及他们的变体(主要参考的是Chinese-Text-Classification-Pytorch这个项目)，目前这些深度学习模型通过参数优化后每个单模Kfold的分数能达到0.90+，最好的单模分数是0.911+；然后是预训练模型，通过一些赛道三的周周星分享的经验，训练nezha-large,并进行微调。最高分数也在0.911+。
5. 关于炼丹(调参)，这个题目比较玄学，调参好像收益比较大。之前有过一次改了一个参数从分数涨了半个百分点。值得一提的是，当你做了某些操作后分数没有提高，不一定是该操作没用，多试一些参数后再下结论。调参主要影响比较大的有batch_size、lr、词向量相关、数据增强相关、模型网络结构相关(这个收益挺大的)。
6. 模型融合方面，整个赛程做了很多尝试，产生了接近10个0.905以上的模型，融合到0.916+，模型融合的收益挺大。最好成绩0.917是三个0.911的模型平均融合的，发现并不是模型越多越好。还是有点看人品。。
7. 个人感觉初赛的难点在于数据量比较小，容易过拟合，线上分数比较抖。希望复赛数据量多了一些之后会好一点。这个比赛会一直做到最后，希望大家都有一个好成绩。

